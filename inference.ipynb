{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from option.coordinet_option import CoordiNetOption\n",
    "from utils.utils import *\n",
    "from model.coordinet import CoordiNetSystem\n",
    "from dataset.cambridge import CambridgeDataset\n",
    "from dataset.seven_scenes import SevenScenesDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load data of scene \"fire\", split: train\n",
      "load data of scene \"fire\", split: valid\n"
     ]
    }
   ],
   "source": [
    "opt_path='/root/coordinet/runs/coordinet/church_train_synthesis2/opt.pkl'\n",
    "with open(opt_path, 'rb') as f:\n",
    "    opt = pickle.load(f)\n",
    "    opt.reshape_size=320\n",
    "    opt.crop_size=300\n",
    "    opt.fixed_weight=False\n",
    "    opt.backbone='efficientnet'\n",
    "    opt.chunk=8\n",
    "# dataset\n",
    "train_dataset = CambridgeDataset(opt.data_root_dir, opt.scene, 'train',opt.reshape_size, opt.crop_size)\n",
    "# train_dataset= SevenScenesDataset(opt.data_root_dir, opt.scene, 'train', opt.reshape_size, opt.crop_size)\n",
    "valid_dataset = CambridgeDataset(opt.data_root_dir, opt.scene, 'valid',opt.reshape_size, opt.crop_size)\n",
    "# valid_dataset= SevenScenesDataset(opt.data_root_dir, opt.scene, 'valid', opt.reshape_size, opt.crop_size)\n",
    "valid_dataloader = DataLoader(valid_dataset, batch_size=opt.chunk, num_workers=16, shuffle=False)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=opt.chunk, num_workers=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b3\n",
      "load model from /root/coordinet/runs/coordinet/fire/ckpt_epoch112_steps100_angle17.2935_t0.3746.pkl\n"
     ]
    }
   ],
   "source": [
    "# init model\n",
    "ckpt_path = '/root/coordinet/runs/coordinet/church_train_synthesis2/ckpt_epoch133_steps1006_angle5.1000_t1.1074.pkl'\n",
    "opt.var_min=[0.25,0.25,0.25,0.0314]\n",
    "coordinet = CoordiNetSystem(opt.feature_dim,opt.W,opt.loss_type,opt.learn_beta,opt.var_min,opt.fixed_weight,opt.backbone,opt.backbone_path)\n",
    "ckpt = torch.load(ckpt_path)\n",
    "coordinet.load_state_dict(ckpt['coordinet'])\n",
    "print('load model from {}'.format(ckpt_path))\n",
    "coordinet = coordinet.cuda()\n",
    "coordinet.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [00:04<01:52,  1.16s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.8/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3483.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:09<00:00, 10.47it/s]\n",
      "[valid] angle_diff:17.2935°, t_diff:0.3746m\n"
     ]
    }
   ],
   "source": [
    "# valid: center crop from test set\n",
    "t_diffs = []\n",
    "angle_diffs = []\n",
    "ts=[]\n",
    "for imgs, poses in tqdm(valid_dataloader, total=len(valid_dataloader), file=sys.stdout):\n",
    "    imgs = imgs.cuda()\n",
    "    poses = poses.cuda()\n",
    "    poses[:,:,-1]=poses[:,:,-1]\n",
    "    with torch.no_grad():\n",
    "        t, q, _, losses = coordinet.forward(imgs, cal_loss=True, y_pose=poses)\n",
    "    ts.append(t.cpu().numpy())\n",
    "    t_diffs.append(losses['t_diff'].cpu().numpy())\n",
    "    angle_diffs.append(losses['angle_diff'].cpu().numpy())\n",
    "t_diffs = np.hstack(t_diffs)\n",
    "angle_diffs = np.hstack(angle_diffs) / np.pi * 180\n",
    "angle_diff = np.median(angle_diffs)\n",
    "t_diff = np.median(np.hstack(t_diffs))\n",
    "print('[valid][median] angle_diff:%.4f°, t_diff:%.4fm' % (angle_diff, t_diff))\n",
    "\n",
    "ts=np.vstack(ts)\n",
    "# save\n",
    "with open('./valid_median_diff.txt', 'w') as f:\n",
    "    for i in range(len(t_diffs)):\n",
    "        GT_t=valid_dataset.test_poses[i][:3,3]\n",
    "        t=ts[i]\n",
    "        f.write('%.4fm %.4f° [GT:(%.3f,%.3f,%.3f)] [Re:(%.3f,%.3f,%.3f)]\\n' % (t_diffs[i], angle_diffs[i],*list(GT_t),*list(t)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [10:12<00:00,  3.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[test] angle_diff:17.1682°, t_diff:0.5989m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# test: uniform num crops from test set\n",
    "t_diffs = []\n",
    "angle_diffs = []\n",
    "ts=[]\n",
    "num_crops=128\n",
    "print('every test image random uniform crop %d times' % num_crops)\n",
    "for i in tqdm(range(len(valid_dataset.test_paths))):\n",
    "    imgs,poses=valid_dataset.uniform_crop(valid_dataset.test_paths[i],num_crops,valid_dataset.test_poses[i])\n",
    "    it,it_diffs,iangle_diffs=[],[],[]\n",
    "    for j in range(0,len(imgs),opt.chunk):\n",
    "        img,pose=imgs[j:j+opt.chunk],poses[j:j+opt.chunk]\n",
    "        img,pose=img.cuda(),pose.cuda()\n",
    "        with torch.no_grad():\n",
    "            t, q, _, losses = coordinet.forward(img, cal_loss=True, y_pose=pose)\n",
    "        it.append(t.cpu().numpy())\n",
    "        it_diffs.append(losses['t_diff'].cpu().numpy())\n",
    "        iangle_diffs.append(losses['angle_diff'].cpu().numpy())\n",
    "    it = np.vstack(it)\n",
    "    it_diffs = np.hstack(it_diffs)\n",
    "    iangle_diffs = np.hstack(iangle_diffs) / np.pi * 180\n",
    "    ts.append(np.mean(it,axis=0))\n",
    "    t_diffs.append(np.mean(it_diffs))\n",
    "    angle_diffs.append(np.mean(iangle_diffs))\n",
    "t_diffs = np.hstack(t_diffs)\n",
    "angle_diffs = np.hstack(angle_diffs)\n",
    "t_diff=np.median(t_diffs)\n",
    "angle_diff=np.median(angle_diffs)\n",
    "print('[test][median] angle_diff:%.4f°, t_diff:%.4fm' % (angle_diff, t_diff))\n",
    "ts=np.vstack(ts)\n",
    "# save\n",
    "with open('./test_median_diff.txt', 'w') as f:\n",
    "    for i in range(len(t_diffs)):\n",
    "        GT_t=valid_dataset.test_poses[i][:3,3]\n",
    "        t=ts[i]\n",
    "        f.write('%.4fm %.4f° [GT:(%.3f,%.3f,%.3f)] [Re:(%.3f,%.3f,%.3f)]\\n' % (t_diffs[i], angle_diffs[i],*list(GT_t),*list(t)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train\n",
    "coordinet.eval()\n",
    "t_diffs = []\n",
    "angle_diffs = []\n",
    "for imgs, poses in tqdm(train_dataloader, total=len(train_dataloader), file=sys.stdout):\n",
    "    imgs = imgs.cuda()\n",
    "    poses = poses.cuda()\n",
    "    with torch.no_grad():\n",
    "        t, q, _, losses = coordinet.forward(imgs, cal_loss=True, y_pose=poses)\n",
    "    t_diffs.append(losses['t_diff'].cpu().numpy())\n",
    "    angle_diffs.append(losses['angle_diff'].cpu().numpy())\n",
    "t_diffs = np.hstack(t_diffs)\n",
    "angle_diffs = np.hstack(angle_diffs) / np.pi * 180\n",
    "angle_diff = np.mean(angle_diffs)\n",
    "t_diff = np.mean(t_diffs)\n",
    "print('[train][mean] angle_diff:%.4f°, t_diff:%.4fm' % (angle_diff, t_diff))\n",
    "# save\n",
    "with open('./train_mean_diff.txt', 'w') as f:\n",
    "    for i in range(len(t_diffs)):\n",
    "        f.write('%.4fm %.4f°\\n' % (t_diffs[i], angle_diffs[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
